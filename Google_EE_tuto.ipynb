{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import ee\n",
    "import geemap\n",
    "import folium\n",
    "import ipywidgets\n",
    "import ipyleaflet\n",
    "import pandas as pd\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install geemap ipywidgets ipyleaflet folium\n"
   ],
   "id": "f920eba7b40fb3cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Force re-authentication\n",
    "ee.Authenticate()"
   ],
   "id": "a30a02dd18a04900",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set Google Earth Engine Project (Replace with your project ID)\n",
    "PROJECT_ID = \"miningcandb\"  # Replace with your actual GEE project ID\n",
    "\n",
    "# Initialize Earth Engine with the project\n",
    "ee.Initialize(project=PROJECT_ID)\n",
    "\n",
    "print(\"✅ Earth Engine is now initialized with project:\", PROJECT_ID)"
   ],
   "id": "9904b1ad2ddad704",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f6fd3cd0a08c5cfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature Method\n",
    "-    .geometry() → Returns the feature’s geometry.\n",
    "-   .propertyNames() → Lists available properties.\n",
    "-   .get(\"property_name\") → Gets a specific property.\n",
    "-   .toDictionary().getInfo() → Converts all feature properties into a Python dictionary."
   ],
   "id": "8a78919565766ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Image Methods (for working with raster datasets)\n",
    "-   .sample() → Samples pixel values at given points.\n",
    "-   .reduceRegion() → Aggregates values over a specific area.\n",
    "-   .clip(geometry) → Clips the raster to a defined region."
   ],
   "id": "f2fa8b06549dc826"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Filtering and reducing data \n",
    "- .filterBounds(geometry) → Returns only features within a given boundary.\n",
    "- .filterMetadata(\"property\", \"equals\", value) → Filters by attribute value."
   ],
   "id": "79f38d46f26a8fde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = ee.FeatureCollection(\"WRI/Aqueduct_Water_Risk/V4/baseline_annual\")\n",
    "# Get first features\n",
    "first_feature = dataset.first().toDictionary().getInfo()\n",
    "print(first_feature)\n",
    "# Get available property names\n",
    "properties = dataset.first().propertyNames().getInfo()\n",
    "print(\"Available properties:\", properties)\n",
    "# Get dictionary of the first feature\n",
    "first_feature = dataset.first().toDictionary().getInfo()\n",
    "\n",
    "# Print all key-value pairs\n",
    "for key, value in first_feature.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ],
   "id": "2311d125393bebaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bcbdfcdf7de2a963",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3bfc5983f945ad37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "648e60c9775b04a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Maps ",
   "id": "69fad0fb543222d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Does not display in PyCharm because of missing widget support \n",
    "Map = geemap.Map()\n",
    "Map"
   ],
   "id": "6463290bb2eef264",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Instead we can use folium or ipyleaflet \n",
    "m = folium.Map(location=[46.5, -81.0], zoom_start=6)\n",
    "folium.Marker([46.5, -81.0], popup=\"Sudbury Mining Site\").add_to(m)\n",
    "m"
   ],
   "id": "58f346804a2bf1e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extract data ",
   "id": "ef50ce6727574532"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "facility_df = pd.read_csv(r'data/Tables/facility_df.csv')\n",
    "facility_df"
   ],
   "id": "1882b60f06bc1fbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "countries = ee.FeatureCollection(\"put your dataset ID\")\n",
    "roi = countries.filter(ee.Filter.eq('countr_na', 'Swaziland'))\n",
    "Map.addLayer(roi, {}, 'Canada')\n",
    "Map.centerObject(roi, 8);\n",
    "Map\n",
    "\n",
    "landsat = ee.ImageCollection('LANDSAT/LC08/C01/T1_L2').filterDate('2016-01-01', '2016-12-31').filterBounds(roi)\n",
    "\n",
    "# Remove clouds\n",
    "composite = ee.Algorithms."
   ],
   "id": "a7dd3515f6e366f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b2ca1766e84bccba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Air pollution",
   "id": "5b4d17b2475870b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function to extract data ",
   "id": "dca41ef4d186b74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_pollution_data(facility_df, start_date=\"2023-01-01\", end_date=\"2023-12-31\"):\n",
    "    \"\"\"\n",
    "    Extracts air pollution data (SO₂, NO₂, CO, PM2.5) from Sentinel-5P for given facilities and prints execution time.\n",
    "\n",
    "    Parameters:\n",
    "    - facility_df (pd.DataFrame): DataFrame with columns ['facility_id', 'facility_name', 'latitude', 'longitude']\n",
    "    - start_date (str): Start date for data extraction (format: \"YYYY-MM-DD\")\n",
    "    - end_date (str): End date for data extraction (format: \"YYYY-MM-DD\")\n",
    "\n",
    "    Returns:\n",
    "    - pollution_df (pd.DataFrame): DataFrame with pollution data for each facility with mean data for the selected date\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_cols = {\"facility_id\", \"facility_name\", \"latitude\", \"longitude\"}\n",
    "    if not required_cols.issubset(facility_df.columns):\n",
    "        raise ValueError(f\"Missing required columns in facility_df: {required_cols - set(facility_df.columns)}\")\n",
    "\n",
    "    # Define Sentinel-5P datasets for pollutants and their units\n",
    "    pollutant_bands = {\n",
    "        \"SO2\": (\"COPERNICUS/S5P/OFFL/L3_SO2\", \"SO2_column_number_density\", \"mol/m²\"),  # Moles per square meter\n",
    "        \"NO2\": (\"COPERNICUS/S5P/OFFL/L3_NO2\", \"NO2_column_number_density\", \"mol/m²\"),\n",
    "        \"CO\": (\"COPERNICUS/S5P/OFFL/L3_CO\", \"CO_column_number_density\", \"mol/m²\"),\n",
    "        \"O3\": (\"COPERNICUS/S5P/OFFL/L3_O3\", \"O3_column_number_density\", \"mol/m²\"),\n",
    "        \"PM2.5\": (\"COPERNICUS/S5P/NRTI/L3_AER_AI\", \"absorbing_aerosol_index\", \"unitless\"),  # Aerosol Index (AI)\n",
    "        \"CH4\": (\"COPERNICUS/S5P/OFFL/L3_CH4\", \"CH4_column_volume_mixing_ratio_dry_air\", \"ppb\"),\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "\n",
    "    # Process each facility\n",
    "    for index, row in facility_df.iterrows():\n",
    "        facility_id = row[\"facility_id\"]\n",
    "        facility_name = row[\"facility_name\"]\n",
    "        lat, lon = row[\"latitude\"], row[\"longitude\"]\n",
    "        facility_location = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "        # Store extracted values\n",
    "        facility_data = {\n",
    "            \"facility_id\": facility_id,\n",
    "            \"facility_name\": facility_name,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon\n",
    "        }\n",
    "\n",
    "        # Extract pollution data for each pollutant\n",
    "        for pollutant, (dataset, band, unit) in pollutant_bands.items():\n",
    "            try:\n",
    "                # Load dataset, filter by date and location\n",
    "                pollution_data = (ee.ImageCollection(dataset)\n",
    "                                  .filterBounds(facility_location)\n",
    "                                  .filterDate(start_date, end_date)\n",
    "                                  .select(band)\n",
    "                                  .mean())  # Compute average over the period\n",
    "\n",
    "                # Reduce region to extract pollution value at the facility location\n",
    "                pollution_value = pollution_data.reduceRegion(\n",
    "                    reducer=ee.Reducer.mean(),\n",
    "                    geometry=facility_location,\n",
    "                    scale=5000,  # 5 km resolution for most pollutants\n",
    "                    bestEffort=True\n",
    "                ).get(band)\n",
    "\n",
    "                # Convert Earth Engine object to Python\n",
    "                facility_data[pollutant] = pollution_value.getInfo() if pollution_value else None\n",
    "                facility_data[f\"{pollutant}_unit\"] = unit  # Add unit\n",
    "            except Exception as e:\n",
    "                facility_data[pollutant] = None  # Handle cases where no data is available\n",
    "                facility_data[f\"{pollutant}_unit\"] = unit\n",
    "\n",
    "        # Append results\n",
    "        results.append(facility_data)\n",
    "\n",
    "        # Progress tracking\n",
    "        if index % 10 == 0:\n",
    "            print(f\"Processed {index + 1}/{len(facility_df)} facilities...\")\n",
    "\n",
    "    # Compute total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"✅ Extraction completed in {total_time:.2f} seconds ({total_time / 60:.2f} minutes)\")\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    pollution_df = pd.DataFrame(results)\n",
    "\n",
    "    return pollution_df"
   ],
   "id": "221697c0cdf2b536",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_df = extract_pollution_data(facility_df)",
   "id": "53446629fb132676",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_pollution_for_table(df):\n",
    "    \"\"\"\n",
    "    Reformats the pollution DataFrame by merging the unit information into column names\n",
    "    and removing unnecessary '_unit' columns. Includes debugging steps.\n",
    "    \"\"\"\n",
    "    new_columns = {}\n",
    "    unit_columns = [col for col in df.columns if col.endswith(\"_unit\")]\n",
    "    \n",
    "    # Iterate through columns and match pollutant columns with their unit columns\n",
    "    for col in df.columns:\n",
    "        if col.endswith(\"_unit\"):\n",
    "            pollutant = col.replace(\"_unit\", \"\")\n",
    "            if pollutant in df.columns:\n",
    "                # Rename main pollutant column with unit in parentheses\n",
    "                unit_value = df[col].iloc[0] if pd.notna(df[col].iloc[0]) else \"unknown_unit\"\n",
    "                new_columns[pollutant] = f\"{pollutant} ({unit_value})\"\n",
    "            new_columns[col] = None  # Mark for removal\n",
    "        else:\n",
    "            if col not in new_columns:\n",
    "                new_columns[col] = col  # Keep unchanged columns\n",
    "\n",
    "    # Apply renaming and drop unnecessary columns\n",
    "    formatted_df = df.rename(columns={k: v for k, v in new_columns.items() if v is not None})\n",
    "    \n",
    "    # Drop '_unit' columns if they exist in the DataFrame\n",
    "    formatted_df = formatted_df.drop(columns=[col for col in unit_columns if col in formatted_df.columns], errors=\"ignore\")\n",
    "    \n",
    "    return formatted_df"
   ],
   "id": "839cdfbcb08de54e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pollution_df = format_pollution_for_table(pollution_df)\n",
    "pollution_df"
   ],
   "id": "ac206fd901fcd837",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_df.to_csv(r'data/Satellite_outputs/tropomi_2023.csv', index=False)",
   "id": "68958389842fd9c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_df.columns",
   "id": "26a67fc9f4e571fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_df = pd.read_csv(r'data/Satellite_outputs/tropomi_2023.csv')",
   "id": "43e2fc82d39b759d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_df",
   "id": "a86f83690a49f7dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- FIX PM2.5 NEGATIVE VALUES ---\n",
    "pollution_df[\"PM2.5 (unitless)\"] = pollution_df[\"PM2.5 (unitless)\"].clip(lower=0)\n",
    "pollution_df"
   ],
   "id": "d2291db137269703",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualization",
   "id": "ae67cc09435cf386"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import folium\n",
    "import branca.colormap as cm\n",
    "from shapely.geometry import Point"
   ],
   "id": "37af7f947c663ccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- FUNCTION FOR POLLUTION MAP WITH REGULATION-BASED THRESHOLDS ---\n",
    "def visualize_pollution_map_thresholds(pollution_df, pollutant_key):\n",
    "    \"\"\"\n",
    "    Creates an interactive map with pollution data using regulatory-based thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    - pollution_df (pd.DataFrame): DataFrame with pollution values.\n",
    "    - pollutant_key (str): The column name representing the pollutant to visualize.\n",
    "    \n",
    "    Returns:\n",
    "    - Folium map with pollution data visualization.\n",
    "    \"\"\"\n",
    "    if pollutant_key not in pollution_df.columns:\n",
    "        raise ValueError(f\"Pollutant '{pollutant_key}' not found in dataframe columns: {pollution_df.columns.tolist()}\")\n",
    "    \n",
    "    # Define map center\n",
    "    map_center = [pollution_df[\"latitude\"].mean(), pollution_df[\"longitude\"].mean()]\n",
    "    m = folium.Map(location=map_center, zoom_start=5, control_scale=True)\n",
    "    \n",
    "    # Define thresholds based on regulatory values\n",
    "    thresholds = {\n",
    "        \"SO2 (mol/m²)\": [0.0002, 0.0005],  # Example values based on air quality guidelines\n",
    "        \"NO2 (mol/m²)\": [0.0001, 0.0003],\n",
    "        \"CO (mol/m²)\": [0.03, 0.05],\n",
    "        \"O3 (mol/m²)\": [0.15, 0.2],\n",
    "        \"PM2.5 (unitless)\": [5, 15],  # Placeholder values, adjust based on standards\n",
    "        \"CH4 (ppb)\": [1850, 1900]  # Placeholder values for methane concentration\n",
    "    }\n",
    "    \n",
    "    def get_regulatory_color(value, pollutant):\n",
    "        if pd.isna(value):\n",
    "            return \"gray\"\n",
    "        limits = thresholds.get(pollutant, [float(\"inf\"), float(\"inf\")])\n",
    "        if value < limits[0]:\n",
    "            return \"green\"\n",
    "        elif value < limits[1]:\n",
    "            return \"yellow\"\n",
    "        else:\n",
    "            return \"red\"\n",
    "    \n",
    "    for _, row in pollution_df.iterrows():\n",
    "        popup_info = f\"\"\"\n",
    "        <b>{row[\"facility_name\"]}</b><br>\n",
    "        {pollutant_key}: {row.get(pollutant_key, \"N/A\")}\n",
    "        \"\"\"\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "            radius=5,\n",
    "            color=get_regulatory_color(row[pollutant_key], pollutant_key),\n",
    "            fill=True,\n",
    "            fill_color=get_regulatory_color(row[pollutant_key], pollutant_key),\n",
    "            fill_opacity=0.8,\n",
    "            popup=folium.Popup(popup_info, max_width=300)\n",
    "        ).add_to(m)\n",
    "    return m\n",
    "\n",
    "# --- FUNCTION FOR POLLUTION MAP WITH CONTINUOUS COLOR SCALE ---\n",
    "def visualize_pollution_map_continuous(pollution_df, pollutant_key):\n",
    "    \"\"\"\n",
    "    Creates an interactive map with pollution data using a continuous color scale.\n",
    "    \n",
    "    Parameters:\n",
    "    - pollution_df (pd.DataFrame): DataFrame with pollution values.\n",
    "    - pollutant_key (str): The column name representing the pollutant to visualize.\n",
    "    \n",
    "    Returns:\n",
    "    - Folium map with pollution data visualization.\n",
    "    \"\"\"\n",
    "    if pollutant_key not in pollution_df.columns:\n",
    "        raise ValueError(f\"Pollutant '{pollutant_key}' not found in dataframe columns: {pollution_df.columns.tolist()}\")\n",
    "    \n",
    "    # Define map center\n",
    "    map_center = [pollution_df[\"latitude\"].mean(), pollution_df[\"longitude\"].mean()]\n",
    "    m = folium.Map(location=map_center, zoom_start=5, control_scale=True)\n",
    "    \n",
    "    # Define continuous color scale correctly\n",
    "    min_pollution = pollution_df[pollutant_key].min()\n",
    "    max_pollution = pollution_df[pollutant_key].max()\n",
    "    colormap = cm.LinearColormap(colors=['green', 'yellow', 'red'], vmin=min_pollution, vmax=max_pollution)\n",
    "    \n",
    "    for _, row in pollution_df.iterrows():\n",
    "        popup_info = f\"\"\"\n",
    "        <b>{row[\"facility_name\"]}</b><br>\n",
    "        {pollutant_key}: {row.get(pollutant_key, \"N/A\")}\n",
    "        \"\"\"\n",
    "        folium.CircleMarker(\n",
    "            location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "            radius=5,\n",
    "            color=colormap(row[pollutant_key]),\n",
    "            fill=True,\n",
    "            fill_color=colormap(row[pollutant_key]),\n",
    "            fill_opacity=0.8,\n",
    "            popup=folium.Popup(popup_info, max_width=300)\n",
    "        ).add_to(m)\n",
    "    \n",
    "    colormap.add_to(m)\n",
    "    return m"
   ],
   "id": "3dd654f06966377",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_pollution_map_continuous(pollution_df, pollutant_key=\"NO2 (mol/m²)\")",
   "id": "1211b0bb46e23c9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- HISTOGRAM VISUALIZATION ---\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle(\"Pollutant Distributions in TROPOMI 2023 Dataset\", fontsize=16)\n",
    "\n",
    "# List of pollutants\n",
    "pollutants = [\"SO2 (mol/m²)\", \"NO2 (mol/m²)\", \"CO (mol/m²)\", \"O3 (mol/m²)\", \"PM2.5 (unitless)\", \"CH4 (ppb)\"]\n",
    "\n",
    "# Plot histograms for each pollutant\n",
    "for ax, pollutant in zip(axes.flatten(), pollutants):\n",
    "    sns.histplot(pollution_df[pollutant].dropna(), bins=30, kde=True, ax=ax)\n",
    "    ax.set_title(f\"{pollutant} Distribution\")\n",
    "    ax.set_xlabel(pollutant)\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ],
   "id": "aec0364fd655a5f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --- SPATIAL VISUALIZATION OF SO2 LEVELS ---\n",
    "# Convert to GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(pollution_df[\"longitude\"], pollution_df[\"latitude\"])]\n",
    "geo_df = gpd.GeoDataFrame(pollution_df, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "# Plot SO2 levels spatially\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "geo_df.plot(column=\"SO2 (mol/m²)\", cmap=\"Reds\", markersize=50, alpha=0.7, legend=True, ax=ax)\n",
    "ax.set_title(\"Spatial Distribution of SO₂ Levels (mol/m²) at Mining Facilities\", fontsize=14)\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "65a970a59b1029f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from db_creation_function import assign_row_id",
   "id": "e6a96a50c34a8c1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_satellite_df = assign_row_id(pollution_df, id_column='id', prefix='pollution_satellite')",
   "id": "fcbc94afb7b24d98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pollution_df.to_csv(r'data/Tables/tropomi_table.csv', index=False)",
   "id": "15c337946d617bca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Land cover",
   "id": "1fa9479fb7f93df5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_land_cover(facility_df, years=[2023], quarters=False):\n",
    "    \"\"\"\n",
    "    Extracts land cover data from ESA WorldCover (yearly) and Dynamic World (optional quarterly) for given facilities.\n",
    "\n",
    "    Parameters:\n",
    "    - facility_df (pd.DataFrame): DataFrame with columns ['facility_id', 'facility_name', 'latitude', 'longitude']\n",
    "    - years (list): List of years to extract data for (default: [2023])\n",
    "    - quarters (bool): If True, extract Dynamic World data quarterly instead of yearly.\n",
    "\n",
    "    Returns:\n",
    "    - land_cover_df (pd.DataFrame): DataFrame with land cover information for each facility.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required_cols = {\"facility_id\", \"facility_name\", \"latitude\", \"longitude\"}\n",
    "    if not required_cols.issubset(facility_df.columns):\n",
    "        raise ValueError(f\"Missing required columns in facility_df: {required_cols - set(facility_df.columns)}\")\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "\n",
    "    # Process each facility\n",
    "    for index, row in facility_df.iterrows():\n",
    "        facility_id = row[\"facility_id\"]\n",
    "        facility_name = row[\"facility_name\"]\n",
    "        lat, lon = row[\"latitude\"], row[\"longitude\"]\n",
    "        facility_location = ee.Geometry.Point([lon, lat])\n",
    "\n",
    "        # Store extracted values\n",
    "        facility_data = {\n",
    "            \"facility_id\": facility_id,\n",
    "            \"facility_name\": facility_name,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon\n",
    "        }\n",
    "\n",
    "        # Extract ESA WorldCover data (yearly updates)\n",
    "        for year in years:\n",
    "            try:\n",
    "                dataset = f\"ESA/WorldCover/v100/{year}\"\n",
    "                band = \"Map\"\n",
    "\n",
    "                # Load dataset and extract land cover classification\n",
    "                land_cover_image = ee.ImageCollection(dataset).filterBounds(facility_location).first()\n",
    "                land_cover_value = land_cover_image.reduceRegion(\n",
    "                    reducer=ee.Reducer.mode(),\n",
    "                    geometry=facility_location,\n",
    "                    scale=10,\n",
    "                    bestEffort=True\n",
    "                ).get(band)\n",
    "\n",
    "                # Convert EE object to Python\n",
    "                facility_data[f\"ESA_WorldCover_{year}\"] = land_cover_value.getInfo() if land_cover_value else None\n",
    "            except Exception:\n",
    "                facility_data[f\"ESA_WorldCover_{year}\"] = None\n",
    "\n",
    "        # Extract Dynamic World land cover data (quarterly or yearly)\n",
    "        for year in years:\n",
    "            if quarters:\n",
    "                # Extract quarterly data\n",
    "                for quarter, month in enumerate([1, 4, 7, 10], start=1):\n",
    "                    try:\n",
    "                        dataset = \"GOOGLE/DYNAMICWORLD/V1\"\n",
    "                        band = \"label\"\n",
    "\n",
    "                        start_date = f\"{year}-{str(month).zfill(2)}-01\"\n",
    "                        end_date = f\"{year}-{str(month + 2).zfill(2)}-28\"\n",
    "\n",
    "                        land_cover_image = ee.ImageCollection(dataset) \\\n",
    "                            .filterBounds(facility_location) \\\n",
    "                            .filterDate(start_date, end_date) \\\n",
    "                            .first()\n",
    "\n",
    "                        land_cover_value = land_cover_image.reduceRegion(\n",
    "                            reducer=ee.Reducer.mode(),\n",
    "                            geometry=facility_location,\n",
    "                            scale=10,\n",
    "                            bestEffort=True\n",
    "                        ).get(band)\n",
    "\n",
    "                        # Convert EE object to Python\n",
    "                        facility_data[f\"Dynamic_World_{year}_Q{quarter}\"] = land_cover_value.getInfo() if land_cover_value else None\n",
    "                    except Exception:\n",
    "                        facility_data[f\"Dynamic_World_{year}_Q{quarter}\"] = None\n",
    "            else:\n",
    "                # Extract yearly Dynamic World data\n",
    "                try:\n",
    "                    dataset = \"GOOGLE/DYNAMICWORLD/V1\"\n",
    "                    band = \"label\"\n",
    "\n",
    "                    start_date = f\"{year}-01-01\"\n",
    "                    end_date = f\"{year}-12-31\"\n",
    "\n",
    "                    land_cover_image = ee.ImageCollection(dataset) \\\n",
    "                        .filterBounds(facility_location) \\\n",
    "                        .filterDate(start_date, end_date) \\\n",
    "                        .first()\n",
    "\n",
    "                    land_cover_value = land_cover_image.reduceRegion(\n",
    "                        reducer=ee.Reducer.mode(),\n",
    "                        geometry=facility_location,\n",
    "                        scale=10,\n",
    "                        bestEffort=True\n",
    "                    ).get(band)\n",
    "\n",
    "                    # Convert EE object to Python\n",
    "                    facility_data[f\"Dynamic_World_{year}\"] = land_cover_value.getInfo() if land_cover_value else None\n",
    "                except Exception:\n",
    "                    facility_data[f\"Dynamic_World_{year}\"] = None\n",
    "\n",
    "        # Append results\n",
    "        results.append(facility_data)\n",
    "\n",
    "        # Progress tracking\n",
    "        if index % 10 == 0:\n",
    "            print(f\"Processed {index + 1}/{len(facility_df)} facilities...\")\n",
    "\n",
    "    # Compute total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"✅ Land cover extraction completed in {total_time:.2f} seconds ({total_time / 60:.2f} minutes)\")\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    land_cover_df = pd.DataFrame(results)\n",
    "\n",
    "    return land_cover_df"
   ],
   "id": "2345db2f1e0ff8b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "land_cover_2023_df = extract_land_cover(facility_df, years=[2021], quarters=False)\n",
    "land_cover_2023_df"
   ],
   "id": "a2bd3b43aabe81eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from db_creation_function import assign_row_id",
   "id": "6cf1f1165a06153a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Re-load required libraries after execution state reset\n",
    "import pandas as pd\n",
    "import ace_tools as tools\n",
    "\n",
    "# Define satellite dataset information\n",
    "satellite_data = [\n",
    "    {\n",
    "        \"Satellite\": \"Sentinel-2 (ESA Copernicus)\",\n",
    "        \"Resolution\": \"10m (RGB, NIR), 20m (other bands)\",\n",
    "        \"Frequency\": \"Every 5 days\",\n",
    "        \"Best For\": \"Land cover, vegetation, mining areas, urbanization\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"Landsat 8 & 9 (NASA/USGS)\",\n",
    "        \"Resolution\": \"30m (multispectral), 15m (panchromatic)\",\n",
    "        \"Frequency\": \"Every 16 days\",\n",
    "        \"Best For\": \"General land-use changes, historical mining analysis\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_TOA\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"MODIS (NASA)\",\n",
    "        \"Resolution\": \"250m (bands 1-2), 500m (other bands)\",\n",
    "        \"Frequency\": \"Daily\",\n",
    "        \"Best For\": \"Large-scale air pollution (PM, CO, NO₂), biomass burning\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MCD12Q1\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"VIIRS (NASA/NOAA)\",\n",
    "        \"Resolution\": \"750m – 1km\",\n",
    "        \"Frequency\": \"Daily\",\n",
    "        \"Best For\": \"Nighttime lights, wildfire detection, emissions tracking\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/NOAA_VIIRS_DNB_MONTHLY_V1_VCMCFG\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"TROPOMI (Sentinel-5P)\",\n",
    "        \"Resolution\": \"5.5 km × 3.5 km\",\n",
    "        \"Frequency\": \"Daily\",\n",
    "        \"Best For\": \"Air pollution (SO₂, NO₂, CO, CH₄), industrial emissions tracking\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_OFFL_L3_NO2\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"GHGSat (Commercial)\",\n",
    "        \"Resolution\": \"~25m (Methane monitoring)\",\n",
    "        \"Frequency\": \"Variable\",\n",
    "        \"Best For\": \"High-resolution CH₄ emissions from industrial sources\",\n",
    "        \"GEE Dataset Link\": \"Not available (commercial data)\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"ECOSTRESS (NASA)\",\n",
    "        \"Resolution\": \"70m\",\n",
    "        \"Frequency\": \"Variable\",\n",
    "        \"Best For\": \"Thermal imaging, industrial heat emissions, energy use analysis\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/NASA_ECO1_LSTE_V001\"\n",
    "    },\n",
    "    {\n",
    "        \"Satellite\": \"ASTER (NASA)\",\n",
    "        \"Resolution\": \"15m (VNIR), 30m (SWIR), 90m (TIR)\",\n",
    "        \"Frequency\": \"On-demand\",\n",
    "        \"Best For\": \"Mineral mapping, geothermal monitoring\",\n",
    "        \"GEE Dataset Link\": \"https://developers.google.com/earth-engine/datasets/catalog/ASTER_GED_V3\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "satellite_df = pd.DataFrame(satellite_data)\n",
    "\n",
    "# Display the table\n",
    "tools.display_dataframe_to_user(name=\"LCA-Related Satellite Datasets\", dataframe=satellite_df)\n"
   ],
   "id": "3d4d108e86a996ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65a0baa32cade977",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
